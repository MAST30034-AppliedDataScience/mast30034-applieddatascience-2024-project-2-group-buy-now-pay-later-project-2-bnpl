{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading library\n",
    "from functools import reduce\n",
    "from pyspark.sql import SparkSession, DataFrame, functions as F\n",
    "from pyspark.sql.types import DoubleType, StringType, IntegerType\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Create a Spark Session\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"ETL Pipeline\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .config(\"spark.execturo.memory\", \"2g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can't use `urlretrive` to get the data from Canvas, please download it to your local machine and move it `data/tables`. Then run the code below to unzip the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign data path\n",
    "raw_path = \"../data\"\n",
    "\n",
    "for file in os.listdir(f\"{raw_path}/tables\"):\n",
    "    if file == \".gitkeep\":\n",
    "        continue\n",
    "    with zipfile.ZipFile(f\"{raw_path}/tables/{file}\", \"r\") as zip_ref:\n",
    "        zip_ref.extractall(f\"{raw_path}/\")\n",
    "    os.remove(f\"{raw_path}/tables/{file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform\n",
    "\n",
    "The system use `user_id` as a key for identifying customer in transactions record and fraud probability tables. However, they also have a key-value map of `user_id` and `consumer_id`. We will use `consumer_id` as the only ID for customer. Thus, we will map `user_id` from each table to `consumer_id` and drop the former."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_id(map_df, target_df):\n",
    "    mapped_df = target_df.join(map_df, on=\"user_id\", how=\"inner\")\n",
    "    mapped_df = mapped_df.drop('user_id')\n",
    "    \n",
    "    return mapped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Load consumer info - a key : value map for user_id to consumer_id\n",
    "consumer_info = spark.read.parquet(f\"{raw_path}/tables/consumer_user_details.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all files that need to replace user_id\n",
    "consumer_fraud_rate = spark.read.csv(f\"{raw_path}/tables/consumer_fraud_probability.csv\", header=True, inferSchema=True)\n",
    "consumer_fraud_rate = replace_id(consumer_info, consumer_fraud_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>order_datetime</th><th>fraud_probability</th><th>consumer_id</th></tr>\n",
       "<tr><td>2022-02-20</td><td>9.805431136520959</td><td>1195503</td></tr>\n",
       "<tr><td>2021-08-30</td><td>9.599513915425788</td><td>179208</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------+-----------------+-----------+\n",
       "|order_datetime|fraud_probability|consumer_id|\n",
       "+--------------+-----------------+-----------+\n",
       "|    2022-02-20|9.805431136520959|    1195503|\n",
       "|    2021-08-30|9.599513915425788|     179208|\n",
       "+--------------+-----------------+-----------+"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumer_fraud_rate.limit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transaction data for user_id replacement\n",
    "transaction_p1 = spark.read.parquet(f\"{raw_path}/tables/transactions_20210228_20210827_snapshot\")\n",
    "transaction_p1 = replace_id(consumer_info, transaction_p1)\n",
    "\n",
    "transaction_p2 = spark.read.parquet(f\"{raw_path}/tables/transactions_20210828_20220227_snapshot\")\n",
    "transaction_p2 = replace_id(consumer_info, transaction_p2)\n",
    "\n",
    "transaction_p3 = spark.read.parquet(f\"{raw_path}/tables/transactions_20220228_20220828_snapshot\")\n",
    "transaction_p3 = replace_id(consumer_info, transaction_p3)\n",
    "\n",
    "transaction_records = reduce(DataFrame.unionAll, [transaction_p1, transaction_p2, transaction_p3])\n",
    "transaction_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>merchant_abn</th><th>dollar_value</th><th>order_id</th><th>order_datetime</th><th>consumer_id</th></tr>\n",
       "<tr><td>62191208634</td><td>63.255848959735246</td><td>949a63c8-29f7-4ab...</td><td>2021-08-20</td><td>651338</td></tr>\n",
       "<tr><td>15549624934</td><td>130.3505283105634</td><td>6a84c3cf-612a-457...</td><td>2021-08-20</td><td>179208</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+------------------+--------------------+--------------+-----------+\n",
       "|merchant_abn|      dollar_value|            order_id|order_datetime|consumer_id|\n",
       "+------------+------------------+--------------------+--------------+-----------+\n",
       "| 62191208634|63.255848959735246|949a63c8-29f7-4ab...|    2021-08-20|     651338|\n",
       "| 15549624934| 130.3505283105634|6a84c3cf-612a-457...|    2021-08-20|     179208|\n",
       "+------------+------------------+--------------------+--------------+-----------+"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transaction_records.limit(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that replacing `user_id` to `consumer_id` is done, load all other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>merchant_abn</th><th>order_datetime</th><th>fraud_probability</th></tr>\n",
       "<tr><td>19492220327</td><td>2021-11-28</td><td>44.403658647495355</td></tr>\n",
       "<tr><td>31334588839</td><td>2021-10-02</td><td>42.75530083865367</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+--------------+------------------+\n",
       "|merchant_abn|order_datetime| fraud_probability|\n",
       "+------------+--------------+------------------+\n",
       "| 19492220327|    2021-11-28|44.403658647495355|\n",
       "| 31334588839|    2021-10-02| 42.75530083865367|\n",
       "+------------+--------------+------------------+"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load merchant fraud probability\n",
    "merchant_fraud_rate = spark.read.csv(f\"{raw_path}/tables/merchant_fraud_probability.csv\", header=True, inferSchema=True)\n",
    "merchant_fraud_rate.limit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-----------------------------------------------------------------------------------------------------------------+------------+-------------------------------------------------------------------------------------+--------------+---------+\n",
      "|name                                |tags                                                                                                             |merchant_abn|category                                                                             |revenue_levels|take_rate|\n",
      "+------------------------------------+-----------------------------------------------------------------------------------------------------------------+------------+-------------------------------------------------------------------------------------+--------------+---------+\n",
      "|Felis Limited                       |[(furniture, home furnishings and equipment shops, and manufacturers, except appliances), (e), (take rate: 0.18)]|10023283211 |furniture, home furnishings and equipment shops, and manufacturers, except appliances|e             |0.18     |\n",
      "|Arcu Ac Orci Corporation            |[[cable, satellite, and otHer pay television and radio services), (b), (take rate: 4.22]]                        |10142254217 |cable, satellite, and otHer pay television and radio services                        |b             |4.22     |\n",
      "|Nunc Sed Company                    |[[jewelry, watch, clock, and silverware shops), (b), (take rate: 4.40]]                                          |10165489824 |jewelry, watch, clock, and silverware shops                                          |b             |4.4      |\n",
      "|Ultricies Dignissim Lacus Foundation|[[wAtch, clock, and jewelry repair shops), (b), (take rate: 3.29]]                                               |10187291046 |wAtch, clock, and jewelry repair shops                                               |b             |3.29     |\n",
      "|Enim Condimentum PC                 |[[music shops - musical instruments, pianos, and sheet music), (a), (take rate: 6.33]]                           |10192359162 |music shops - musical instruments, pianos, and sheet music                           |a             |6.33     |\n",
      "|Fusce Company                       |[(gift, card, novelty, and souvenir shops), (a), (take rate: 6.34)]                                              |10206519221 |gift, card, novelty, and souvenir shops                                              |a             |6.34     |\n",
      "|Aliquam Enim Incorporated           |[(computers, comPUter peripheral equipment, and softwAre), (b), (take rate: 4.32)]                               |10255988167 |computers, comPUter peripheral equipment, and softwAre                               |b             |4.32     |\n",
      "|Ipsum Primis Ltd                    |[[watch, clock, and jewelry repair shops), (c), (take rate: 2.39]]                                               |10264435225 |watch, clock, and jewelry repair shops                                               |c             |2.39     |\n",
      "|Pede Ultrices Industries            |[[computer programming , data processing, and integrated systems design services), (a), (take rate: 5.71]]       |10279061213 |computer programming , data processing, and integrated systems design services       |a             |5.71     |\n",
      "|Nunc Inc.                           |[(furniture, home furnishings and equipment shopS, and manufacturers, except appliances), (a), (take rate: 6.61)]|10323485998 |furniture, home furnishings and equipment shopS, and manufacturers, except appliances|a             |6.61     |\n",
      "|Facilisis Facilisis Corp.           |[[computers, computer peripheral equipment, and software), (a), (take rate: 6.34]]                               |10342410215 |computers, computer peripheral equipment, and software                               |a             |6.34     |\n",
      "|Odio Institute                      |[(equipment, tool, furniture, and appliance  rent al and leAsing), (b), (take rate: 3.57)]                       |10346855916 |equipment, tool, furniture, and appliance  rent al and leAsing                       |b             |3.57     |\n",
      "|Rutrum Justo Ltd                    |[[music shops - musical instruments, pianos, and sheet music), (b), (take rate: 3.63]]                           |10364012396 |music shops - musical instruments, pianos, and sheet music                           |b             |3.63     |\n",
      "|Tellus Foundation                   |[[artist supply and craft  shops), (b), (take rate: 3.17]]                                                       |10385011947 |artist supply and craft  shops                                                       |b             |3.17     |\n",
      "|Sed Et Company                      |[[florists supplies, nursery stock, and flowers), (a), (take rate: 6.61]]                                        |10385163239 |florists supplies, nursery stock, and flowers                                        |a             |6.61     |\n",
      "|Id Ltd                              |[[computers, computer peripheral  equipment, and software), (a), (take rate: 5.54]]                              |10385250025 |computers, computer peripheral  equipment, and software                              |a             |5.54     |\n",
      "|Consequat Foundation                |[[antique shops - sales, repairs, and restoration serVices), (a), (take rate: 6.93]]                             |10404542215 |antique shops - sales, repairs, and restoration serVices                             |a             |6.93     |\n",
      "|Sit Amet Nulla Corp.                |[[motor vehicle supplies and new parts), (b), (take rate: 4.97]]                                                 |10430380319 |motor vehicle supplies and new parts                                                 |b             |4.97     |\n",
      "|Massa Vestibulum Foundation         |[(moTor vehicle supplies and new parts), (a), (take rate: 5.77)]                                                 |10441711491 |moTor vehicle supplies and new parts                                                 |a             |5.77     |\n",
      "|Ut Consulting                       |[[gift, card, novelty, and souvenir shops), (c), (take rate: 2.95]]                                              |10462560289 |gift, card, novelty, and souvenir shops                                              |c             |2.95     |\n",
      "+------------------------------------+-----------------------------------------------------------------------------------------------------------------+------------+-------------------------------------------------------------------------------------+--------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load merchant's info\n",
    "merchant_info = spark.read.parquet(f\"{raw_path}/tables/tbl_merchants.parquet\")\n",
    "merchant_info = merchant_info.withColumn(\"tags\", F.regexp_replace(\"tags\", r\"^[\\(\\[]|[\\)\\]]$\", \"\")) # Remove the outermost bracket\n",
    "merchant_info = merchant_info.withColumn(\"tags\", F.regexp_replace(\"tags\", r\"[\\)\\]],\\s*[\\(\\[]\", r\")\\|(\")) # Replacing the comma that seperate each touple/list into \"|\"\n",
    "merchant_info = merchant_info.withColumn(\"tags\", F.split(\"tags\", \"\\|\")) # split accorddingly \n",
    "merchant_info = merchant_info.withColumns({\"category\": F.regexp_replace(F.col(\"tags\").getItem(0), r\"^[\\(\\[]|[\\)\\]]$\", \"\"),\n",
    "                                           \"revenue_levels\": F.regexp_replace(F.col(\"tags\").getItem(1), r\"^[\\(\\[]|[\\)\\]]$\", \"\"),\n",
    "                                           \"take_rate\": F.regexp_extract(F.col(\"tags\").getItem(2), r\"take rate: (\\d+\\.\\d+)\",1).cast(DoubleType())\n",
    "                                          })\n",
    "merchant_info.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>gender</th><th>count</th></tr>\n",
       "<tr><td>Undisclosed</td><td>50074</td></tr>\n",
       "<tr><td>Female</td><td>224946</td></tr>\n",
       "<tr><td>Male</td><td>224979</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+------+\n",
       "|     gender| count|\n",
       "+-----------+------+\n",
       "|Undisclosed| 50074|\n",
       "|     Female|224946|\n",
       "|       Male|224979|\n",
       "+-----------+------+"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load consumer's info and reformat\n",
    "consumer_info = spark.read.csv(f\"{raw_path}/tables/tbl_consumer.csv\", header=True, inferSchema=True)\n",
    "consumer_info = consumer_info.withColumn(\"info\", F.split(F.col(\"name|address|state|postcode|gender|consumer_id\"), \"\\|\")).drop(F.col(\"name|address|state|postcode|gender|consumer_id\"))\n",
    "consumer_info = consumer_info.withColumns({\"consumer_id\": F.col(\"info\").getItem(5),\n",
    "                                           \"name\": F.col(\"info\").getItem(0),\n",
    "                                           \"postcode\": F.col(\"info\").getItem(3).cast(IntegerType()),\n",
    "                                           \"gender\": F.col(\"info\").getItem(4)}).drop(F.col(\"info\"))\n",
    "consumer_info.groupBy(\"gender\").count() # relatively same proportion of female and male customer, only a small percentage of did not provide their gender"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
