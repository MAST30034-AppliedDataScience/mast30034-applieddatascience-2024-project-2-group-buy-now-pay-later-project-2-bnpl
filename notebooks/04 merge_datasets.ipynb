{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join merchant & consumer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Data Merge\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.driver.memory\", \"9g\") \n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join merchant & consumer data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in merchant data (csv)\n",
    "merchant = spark.read.parquet(\"../data/curated/part_1/tbl_merchants.parquet\")\n",
    "\n",
    "# Load in merchant fraud (csv)\n",
    "merchant_fp = pd.read_csv(\"../data/tables/part_1/merchant_fraud_probability.csv\")\n",
    "merchant_fp = spark.createDataFrame(merchant_fp)\n",
    "\n",
    "# Load in consumer list (csv)\n",
    "consumer = pd.read_csv(\"../data/tables/part_1/tbl_consumer.csv\", delimiter=\"|\")\n",
    "consumer = spark.createDataFrame(consumer)\n",
    "\n",
    "# Load in consumer fraud (csv)\n",
    "consumer_fp = pd.read_csv(\"../data/tables/part_1/consumer_fraud_probability.csv\")\n",
    "consumer_fp = spark.createDataFrame(consumer_fp)\n",
    "\n",
    "consumer_ud = spark.read.parquet(\"../data/tables/part_1/consumer_user_details.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Join customer data**\n",
    "\n",
    "`tbl_consumer` to `consumer_user_detail`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining user id to customers\n",
    "consumer = consumer.join(consumer_ud, on = 'consumer_id', how = 'left')\n",
    "consumer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = consumer.select('user_id', 'consumer_id', 'postcode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Join customers and transaction data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read transaction dataset\n",
    "transaction1 = spark.read.parquet(\"../data/tables/part_2\")\n",
    "transaction2 = spark.read.parquet(\"../data/tables/part_3\")\n",
    "transaction3 = spark.read.parquet(\"../data/tables/part_4\")\n",
    "\n",
    "transaction = transaction1.union(transaction2).union(transaction3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join customers to transactions\n",
    "consumer_transaction = transaction.join(consumer, on='user_id', how='left')\n",
    "dropped_consumer_transaction = transaction.join(consumer, on='user_id', how='left_anti') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_transaction.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining customer transaction to merchant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = consumer_transaction.join(merchant_fp, on=['merchant_abn','order_datetime'], how = 'left')\n",
    "final_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.join(consumer_fp, on =['user_id', 'order_datetime'], how = 'left')\n",
    "final_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.write.mode('overwrite').parquet('../data/curated/fraud_watch/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join external datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medians = pd.read_csv(\"../data/curated/sa2_dataset/C21_G02_SA2_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names\n",
    "variables = {1: \"median_age\", \n",
    "             2: \"median_total_personal_income\",\n",
    "             3: \"median_total_family_income\",\n",
    "             4: \"median_total_household_income\",\n",
    "             5: \"median_mortgage_repayment\",\n",
    "             6: \"median_rent\",\n",
    "             7: \"avg_people_per_bedroom\",\n",
    "             8: \"avg_household_size\"}\n",
    "\n",
    "medians = medians.pivot(index='sa2_code', columns=['type_of_value_code'], values='obs_value').reset_index().rename(columns=variables)\n",
    "medians.columns.name = None\n",
    "medians['sa2_code'] = medians.sa2_code.astype(str)\n",
    "\n",
    "medians.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in zone file\n",
    "sa2_boundary_gdf = gpd.read_file(\"../data/curated/sa2_boundary/SA2_2021_AUST_GDA2020_clean.shp\")\n",
    "sa2_names = sa2_boundary_gdf[['sa2_code21', 'sa2_name21']].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find records with null statistics to identify SA2 zones with null median/average values\n",
    "null_regions = medians[medians.isna().any(axis=1)]\n",
    "null_regions = null_regions.merge(sa2_names, left_on='sa2_code', right_on='sa2_code21')\n",
    "null_regions.iloc[:,-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "url = \"\"\"https://github.com/matthewproctor/australianpostcodes/blob/92a036281ee4009be03cca3ab0b8b1a49b21dca7/australian_postcodes.csv\"\"\"\n",
    "base_path = \"../data/tables/poa_dataset\"\n",
    "\n",
    "response = requests.get(url, headers={'accept': 'text/csv'}, stream=True)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)\n",
    "\n",
    "with open(\"../data/tables/poa_dataset/postcodes_to_sa2.csv\", 'wb') as file:\n",
    "    for chunk in response.iter_content(chunk_size=8192):\n",
    "        if chunk:\n",
    "            file.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sa2 - postcodes\n",
    "# write code to come up with useful statistics per "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
