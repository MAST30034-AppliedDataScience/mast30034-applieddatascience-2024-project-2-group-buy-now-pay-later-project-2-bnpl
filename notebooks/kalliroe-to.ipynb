{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "24/09/11 09:17:17 WARN Utils: Your hostname, DESKTOP-702MS12 resolves to a loopback address: 127.0.1.1; using 172.17.210.38 instead (on interface eth0)\n",
      "24/09/11 09:17:17 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/11 09:17:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Data Cleaning\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.driver.memory\", \"9g\") \n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join merchant & consumer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/10 16:03:54 WARN Utils: Your hostname, LAPTOP-406UJ3L3 resolves to a loopback address: 127.0.1.1; using 172.22.104.23 instead (on interface eth0)\n",
      "24/09/10 16:03:54 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/10 16:03:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/09/10 16:03:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Data Merge\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.driver.memory\", \"9g\") \n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join merchant & consumer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_func(left: DataFrame, right: DataFrame, left_keys: ArrayType, \n",
    "              method: StringType='inner', right_keys: ArrayType=None, drop_left: BooleanType=False) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Joins two pyspark dataframes on the left and right specified keys, returning the inner join by default.\n",
    "    Identifies records not joined in left and right datasets.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not right_keys:\n",
    "        right_keys = left_keys\n",
    "\n",
    "    join_cond = \"&\".join([f\"(left.{i} == right.{j})\" for i,j in zip(left_keys, right_keys)])\n",
    "\n",
    "    if not drop_left:\n",
    "        drop_cols = [right[c] for c in right_keys]\n",
    "    else: \n",
    "        drop_cols = [left[c] for c in left_keys]\n",
    "\n",
    "    # Join\n",
    "    joined_df = left.join(right, eval(join_cond), how=method).drop(*drop_cols)\n",
    "\n",
    "    # See which return all the rows from left df that do not have a match in the right df\n",
    "    mismatch = left.join(right, eval(join_cond), how='left_anti').drop(*drop_cols)\n",
    "    print(f\"Number of unjoined left records: {mismatch.count()}\")\n",
    "\n",
    "    return joined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in merchant data (csv)\n",
    "merchant = spark.read.parquet(\"../data/curated/part_1/tbl_merchants.parquet\")\n",
    "\n",
    "# Load in merchant fraud (csv)\n",
    "merchant_fp = pd.read_csv(\"../data/tables/part_1/merchant_fraud_probability.csv\")\n",
    "merchant_fp = spark.createDataFrame(merchant_fp)\n",
    "\n",
    "# Load in consumer list (csv)\n",
    "consumer = pd.read_csv(\"../data/tables/part_1/tbl_consumer.csv\", delimiter=\"|\")\n",
    "consumer = spark.createDataFrame(consumer)\n",
    "\n",
    "# Load in consumer fraud (csv)\n",
    "consumer_fp = pd.read_csv(\"../data/tables/part_1/consumer_fraud_probability.csv\")\n",
    "consumer_fp = spark.createDataFrame(consumer_fp)\n",
    "\n",
    "consumer_ud = spark.read.parquet(\"../data/tables/part_1/consumer_user_details.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Join merchants data**\n",
    "\n",
    "`tbl_merchant` to `merchant_fraud_probability`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unjoined left records: 3978\n",
      "+--------------------+------------+--------------------+-------------+---------+--------------+-----------------+\n",
      "|                name|merchant_abn|               goods|revenue_level|take_rate|order_datetime|fraud_probability|\n",
      "+--------------------+------------+--------------------+-------------+---------+--------------+-----------------+\n",
      "|        Mollis Corp.| 12516851436|watch, clock, and...|            a|     6.71|          NULL|             NULL|\n",
      "|     Ante Industries| 15613631617|motor vehicle sup...|            e|     0.35|          NULL|             NULL|\n",
      "|Pellentesque Habi...| 19839532017|cable, satellite,...|            b|     4.94|          NULL|             NULL|\n",
      "|Mauris Nulla Inte...| 34440496342|opticians, optica...|            c|     2.85|          NULL|             NULL|\n",
      "|Quis Tristique Ac...| 35344855546|watch, clock, and...|            c|     2.92|          NULL|             NULL|\n",
      "+--------------------+------------+--------------------+-------------+---------+--------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merchant_full = join_func(merchant, merchant_fp, ['merchant_abn'], 'left', drop_left=False)\n",
    "merchant_full.orderBy('fraud_probability', ascending=False).limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>merchant_abn</th><th>goods</th><th>revenue_level</th><th>take_rate</th><th>order_datetime</th><th>fraud_probability</th></tr>\n",
       "<tr><td>Tempus Mauris Ltd</td><td>35575706403</td><td>antique shops - s...</td><td>b</td><td>3.46</td><td>2022-02-20</td><td>91.09606847149963</td></tr>\n",
       "<tr><td>Ut Corporation</td><td>97884414539</td><td>antique shops - s...</td><td>a</td><td>6.82</td><td>2021-10-19</td><td>89.79919971536573</td></tr>\n",
       "<tr><td>Duis At Inc.</td><td>14530561097</td><td>jewelry, watch, c...</td><td>c</td><td>1.69</td><td>2021-09-15</td><td>80.80054474543395</td></tr>\n",
       "<tr><td>Ut Industries</td><td>18737319630</td><td>computers, comput...</td><td>a</td><td>5.7</td><td>2021-09-25</td><td>72.73069736562613</td></tr>\n",
       "<tr><td>Mi Eleifend Egest...</td><td>85482742429</td><td>gift, card, novel...</td><td>b</td><td>3.91</td><td>2021-11-27</td><td>70.88131110541714</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+------------+--------------------+-------------+---------+--------------+-----------------+\n",
       "|                name|merchant_abn|               goods|revenue_level|take_rate|order_datetime|fraud_probability|\n",
       "+--------------------+------------+--------------------+-------------+---------+--------------+-----------------+\n",
       "|   Tempus Mauris Ltd| 35575706403|antique shops - s...|            b|     3.46|    2022-02-20|91.09606847149963|\n",
       "|      Ut Corporation| 97884414539|antique shops - s...|            a|     6.82|    2021-10-19|89.79919971536573|\n",
       "|        Duis At Inc.| 14530561097|jewelry, watch, c...|            c|     1.69|    2021-09-15|80.80054474543395|\n",
       "|       Ut Industries| 18737319630|computers, comput...|            a|      5.7|    2021-09-25|72.73069736562613|\n",
       "|Mi Eleifend Egest...| 85482742429|gift, card, novel...|            b|     3.91|    2021-11-27|70.88131110541714|\n",
       "+--------------------+------------+--------------------+-------------+---------+--------------+-----------------+"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant_full.orderBy('fraud_probability', ascending=False).limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Join customer data**\n",
    "\n",
    "`tbl_consumer` to `consumer_user_detail` and `consumer_fraud_probability`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/10 16:17:13 WARN TaskSetManager: Stage 141 contains a task of very large size (1709 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unjoined left records: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/10 16:17:14 WARN TaskSetManager: Stage 148 contains a task of very large size (1709 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unjoined left records: 479871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/10 16:17:15 WARN TaskSetManager: Stage 155 contains a task of very large size (1709 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/09/10 16:17:15 WARN TaskSetManager: Stage 160 contains a task of very large size (1709 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>state</th><th>postcode</th><th>gender</th><th>consumer_id</th><th>user_id</th><th>order_datetime</th><th>fraud_probability</th></tr>\n",
       "<tr><td>Yolanda Williams</td><td>WA</td><td>6935</td><td>Female</td><td>1195503</td><td>1</td><td>2022-02-20</td><td>9.80543113652096</td></tr>\n",
       "<tr><td>Mary Smith</td><td>NSW</td><td>2782</td><td>Female</td><td>179208</td><td>2</td><td>2021-08-30</td><td>9.599513915425788</td></tr>\n",
       "<tr><td>Mary Smith</td><td>NSW</td><td>2782</td><td>Female</td><td>179208</td><td>2</td><td>2021-09-25</td><td>10.069850934775245</td></tr>\n",
       "<tr><td>Jill Jones MD</td><td>NT</td><td>862</td><td>Female</td><td>1194530</td><td>3</td><td>2021-11-03</td><td>8.300636455314633</td></tr>\n",
       "<tr><td>Lindsay Jimenez</td><td>NSW</td><td>2780</td><td>Female</td><td>154128</td><td>4</td><td>2021-10-09</td><td>9.63330241109042</td></tr>\n",
       "<tr><td>Rebecca Blanchard</td><td>WA</td><td>6355</td><td>Female</td><td>712975</td><td>5</td><td>2022-02-08</td><td>9.02022421158597</td></tr>\n",
       "<tr><td>Rebecca Blanchard</td><td>WA</td><td>6355</td><td>Female</td><td>712975</td><td>5</td><td>2021-10-04</td><td>10.868364868449886</td></tr>\n",
       "<tr><td>Rebecca Blanchard</td><td>WA</td><td>6355</td><td>Female</td><td>712975</td><td>5</td><td>2022-01-11</td><td>27.496186536467164</td></tr>\n",
       "<tr><td>Karen Chapman</td><td>NSW</td><td>2033</td><td>Female</td><td>407340</td><td>6</td><td>2021-12-12</td><td>10.459280127078758</td></tr>\n",
       "<tr><td>Andrea Jones</td><td>QLD</td><td>4606</td><td>Female</td><td>511685</td><td>7</td><td>NULL</td><td>NULL</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------------+-----+--------+------+-----------+-------+--------------+------------------+\n",
       "|             name|state|postcode|gender|consumer_id|user_id|order_datetime| fraud_probability|\n",
       "+-----------------+-----+--------+------+-----------+-------+--------------+------------------+\n",
       "| Yolanda Williams|   WA|    6935|Female|    1195503|      1|    2022-02-20|  9.80543113652096|\n",
       "|       Mary Smith|  NSW|    2782|Female|     179208|      2|    2021-08-30| 9.599513915425788|\n",
       "|       Mary Smith|  NSW|    2782|Female|     179208|      2|    2021-09-25|10.069850934775245|\n",
       "|    Jill Jones MD|   NT|     862|Female|    1194530|      3|    2021-11-03| 8.300636455314633|\n",
       "|  Lindsay Jimenez|  NSW|    2780|Female|     154128|      4|    2021-10-09|  9.63330241109042|\n",
       "|Rebecca Blanchard|   WA|    6355|Female|     712975|      5|    2022-02-08|  9.02022421158597|\n",
       "|Rebecca Blanchard|   WA|    6355|Female|     712975|      5|    2021-10-04|10.868364868449886|\n",
       "|Rebecca Blanchard|   WA|    6355|Female|     712975|      5|    2022-01-11|27.496186536467164|\n",
       "|    Karen Chapman|  NSW|    2033|Female|     407340|      6|    2021-12-12|10.459280127078758|\n",
       "|     Andrea Jones|  QLD|    4606|Female|     511685|      7|          NULL|              NULL|\n",
       "+-----------------+-----+--------+------+-----------+-------+--------------+------------------+"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumer_full_ids = join_func(consumer, consumer_ud, ['consumer_id'], 'left') # match user_id to consumers\n",
    "consumer_full = join_func(consumer_full_ids, consumer_fp, ['user_id'], 'left') # match fraud probaibility to consumers\n",
    "\n",
    "# Drop irrelevant columns\n",
    "consumer_full = consumer_full.drop(*['address'])\n",
    "consumer_full.limit(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Join customers and transaction data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read transaction dataset\n",
    "transaction1 = spark.read.parquet(\"../data/tables/part_2\")\n",
    "transaction2 = spark.read.parquet(\"../data/tables/part_3\")\n",
    "transaction3 = spark.read.parquet(\"../data/tables/part_4\")\n",
    "\n",
    "transaction = transaction1.union(transaction2).union(transaction3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/10 16:18:03 WARN TaskSetManager: Stage 176 contains a task of very large size (1709 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 175:===================================================>   (45 + 3) / 48]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 475918 customers with no matching transactions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Join customers to transactions\n",
    "consumer_transaction = consumer_full_ids.join(transaction, on=['user_id'])\n",
    "\n",
    "# Count number of customers in dataset with no transactions\n",
    "mismatch_c_t = consumer_full_ids.join(transaction, on='user_id', how='left_anti')\n",
    "print(f\"There are {mismatch_c_t.count()} customers with no matching transactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- postcode: long (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- consumer_id: long (nullable = true)\n",
      " |-- merchant_abn: long (nullable = true)\n",
      " |-- dollar_value: double (nullable = true)\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- order_datetime: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "consumer_transaction.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/10 16:18:30 WARN TaskSetManager: Stage 186 contains a task of very large size (1709 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/09/10 16:18:47 WARN TaskSetManager: Stage 192 contains a task of very large size (1709 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>user_id</th><th>name</th><th>address</th><th>state</th><th>postcode</th><th>gender</th><th>consumer_id</th><th>merchant_abn</th><th>dollar_value</th><th>order_id</th><th>order_datetime</th></tr>\n",
       "<tr><td>7</td><td>Andrea Jones</td><td>122 Brandon Cliff</td><td>QLD</td><td>4606</td><td>Female</td><td>511685</td><td>33064796871</td><td>373.0873675184212</td><td>fe188788-b89f-4dd...</td><td>2021-08-20</td></tr>\n",
       "<tr><td>7</td><td>Andrea Jones</td><td>122 Brandon Cliff</td><td>QLD</td><td>4606</td><td>Female</td><td>511685</td><td>68435002949</td><td>232.5364986739752</td><td>b4a89891-a113-45e...</td><td>2021-08-20</td></tr>\n",
       "<tr><td>7</td><td>Andrea Jones</td><td>122 Brandon Cliff</td><td>QLD</td><td>4606</td><td>Female</td><td>511685</td><td>41944909975</td><td>30.910755230234322</td><td>302ae628-8eba-4a5...</td><td>2021-08-20</td></tr>\n",
       "<tr><td>7</td><td>Andrea Jones</td><td>122 Brandon Cliff</td><td>QLD</td><td>4606</td><td>Female</td><td>511685</td><td>21439773999</td><td>91.18655746114226</td><td>4524fdc9-73f0-477...</td><td>2021-08-21</td></tr>\n",
       "<tr><td>7</td><td>Andrea Jones</td><td>122 Brandon Cliff</td><td>QLD</td><td>4606</td><td>Female</td><td>511685</td><td>86662713230</td><td>38.8137172956379</td><td>28f9e0f3-858d-445...</td><td>2021-08-19</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+------------+-----------------+-----+--------+------+-----------+------------+------------------+--------------------+--------------+\n",
       "|user_id|        name|          address|state|postcode|gender|consumer_id|merchant_abn|      dollar_value|            order_id|order_datetime|\n",
       "+-------+------------+-----------------+-----+--------+------+-----------+------------+------------------+--------------------+--------------+\n",
       "|      7|Andrea Jones|122 Brandon Cliff|  QLD|    4606|Female|     511685| 33064796871| 373.0873675184212|fe188788-b89f-4dd...|    2021-08-20|\n",
       "|      7|Andrea Jones|122 Brandon Cliff|  QLD|    4606|Female|     511685| 68435002949| 232.5364986739752|b4a89891-a113-45e...|    2021-08-20|\n",
       "|      7|Andrea Jones|122 Brandon Cliff|  QLD|    4606|Female|     511685| 41944909975|30.910755230234322|302ae628-8eba-4a5...|    2021-08-20|\n",
       "|      7|Andrea Jones|122 Brandon Cliff|  QLD|    4606|Female|     511685| 21439773999| 91.18655746114226|4524fdc9-73f0-477...|    2021-08-21|\n",
       "|      7|Andrea Jones|122 Brandon Cliff|  QLD|    4606|Female|     511685| 86662713230|  38.8137172956379|28f9e0f3-858d-445...|    2021-08-19|\n",
       "+-------+------------+-----------------+-----+--------+------+-----------+------------+------------------+--------------------+--------------+"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumer_transaction.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join external datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "medians = pd.read_csv(\"../data/curated/sa2_dataset/C21_G02_SA2_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sa2_code</th>\n",
       "      <th>median_age</th>\n",
       "      <th>median_total_personal_income</th>\n",
       "      <th>median_total_family_income</th>\n",
       "      <th>median_total_household_income</th>\n",
       "      <th>median_mortgage_repayment</th>\n",
       "      <th>median_rent</th>\n",
       "      <th>avg_people_per_bedroom</th>\n",
       "      <th>avg_household_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101021007</td>\n",
       "      <td>51.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>1886.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>1732.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101021008</td>\n",
       "      <td>38.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>2334.0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101021009</td>\n",
       "      <td>37.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>2233.0</td>\n",
       "      <td>1703.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101021010</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1104.0</td>\n",
       "      <td>2412.0</td>\n",
       "      <td>1796.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101021012</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1357.0</td>\n",
       "      <td>3332.0</td>\n",
       "      <td>3014.0</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sa2_code  median_age  median_total_personal_income  \\\n",
       "0  101021007        51.0                         760.0   \n",
       "1  101021008        38.0                         975.0   \n",
       "2  101021009        37.0                         996.0   \n",
       "3  101021010        36.0                        1104.0   \n",
       "4  101021012        37.0                        1357.0   \n",
       "\n",
       "   median_total_family_income  median_total_household_income  \\\n",
       "0                      1886.0                         1429.0   \n",
       "1                      2334.0                         1989.0   \n",
       "2                      2233.0                         1703.0   \n",
       "3                      2412.0                         1796.0   \n",
       "4                      3332.0                         3014.0   \n",
       "\n",
       "   median_mortgage_repayment  median_rent  avg_people_per_bedroom  \\\n",
       "0                     1732.0        330.0                     0.8   \n",
       "1                     1950.0        350.0                     0.8   \n",
       "2                     1700.0        330.0                     0.9   \n",
       "3                     1700.0        310.0                     0.9   \n",
       "4                     2300.0        430.0                     0.8   \n",
       "\n",
       "   avg_household_size  \n",
       "0                 2.2  \n",
       "1                 2.6  \n",
       "2                 2.1  \n",
       "3                 2.1  \n",
       "4                 2.9  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column names\n",
    "variables = {1: \"median_age\", \n",
    "             2: \"median_total_personal_income\",\n",
    "             3: \"median_total_family_income\",\n",
    "             4: \"median_total_household_income\",\n",
    "             5: \"median_mortgage_repayment\",\n",
    "             6: \"median_rent\",\n",
    "             7: \"avg_people_per_bedroom\",\n",
    "             8: \"avg_household_size\"}\n",
    "\n",
    "medians = medians.pivot(index='sa2_code', columns=['type_of_value_code'], values='obs_value').reset_index().rename(columns=variables)\n",
    "medians.columns.name = None\n",
    "medians['sa2_code'] = medians.sa2_code.astype(str)\n",
    "\n",
    "medians.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in zone file\n",
    "sa2_boundary_gdf = gpd.read_file(\"../data/curated/sa2_boundary/SA2_2021_AUST_GDA2020_clean.shp\")\n",
    "sa2_names = sa2_boundary_gdf[['sa2_code21', 'sa2_name21']].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sa2_code21</th>\n",
       "      <th>sa2_name21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sa2_code21, sa2_name21]\n",
       "Index: []"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find records with null statistics to identify SA2 zones with null median/average values\n",
    "null_regions = medians[medians.isna().any(axis=1)]\n",
    "null_regions = null_regions.merge(sa2_names, left_on='sa2_code', right_on='sa2_code21')\n",
    "null_regions.iloc[:,-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "url = \"\"\"https://github.com/matthewproctor/australianpostcodes/blob/92a036281ee4009be03cca3ab0b8b1a49b21dca7/australian_postcodes.csv\"\"\"\n",
    "base_path = \"../data/tables/poa_dataset\"\n",
    "\n",
    "response = requests.get(url, headers={'accept': 'text/csv'}, stream=True)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)\n",
    "\n",
    "with open(\"../data/tables/poa_dataset/postcodes_to_sa2.csv\", 'wb') as file:\n",
    "    for chunk in response.iter_content(chunk_size=8192):\n",
    "        if chunk:\n",
    "            file.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sa2 - postcodes\n",
    "# write code to come up with useful statistics per "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
